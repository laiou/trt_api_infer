# trt_api_infer
### This repo is using tensorrt api infer yolov3 model，now can support int8 fp16 and fp32 precision to infer.
------
### Test Environment:
- Ubuntu18.04LTS
- TensorRT7.0
- Cuda 10.0
------
### Start Using:
&ensp;&ensp;Get the [model](https://pan.baidu.com/s/1XNRdyEPsD8_MA5wlRV1rNQ)pre-prepared model，and place it in model file，

